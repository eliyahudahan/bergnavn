{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20875cdf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks/maritime_analysis.ipynb\n",
    "\"\"\"\n",
    "# Maritime Data Analysis - Data Science Portfolio Project\n",
    "\n",
    "This notebook demonstrates advanced data analysis techniques applied to maritime data.\n",
    "Perfect for showcasing Data Science skills in job interviews.\n",
    "\n",
    "Author: [Your Name]\n",
    "Project: BergNavn Maritime Intelligence Platform\n",
    "Date: December 2024\n",
    "\"\"\"\n",
    "\n",
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cell 2: Load data from API\n",
    "print(\"üì° Loading maritime data from API...\")\n",
    "BASE_URL = \"http://localhost:5000\"  # Change to your server URL\n",
    "\n",
    "try:\n",
    "    # Try to get route data\n",
    "    response = requests.get(f\"{BASE_URL}/maritime/api/analytics/route-statistics\", timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        route_data = response.json()\n",
    "        print(\"‚úÖ Route data loaded successfully\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Could not load route data, using sample data\")\n",
    "        # Load sample data\n",
    "        with open('../backend/assets/sample_routes.json', 'r') as f:\n",
    "            route_data = json.load(f)\n",
    "except:\n",
    "    print(\"‚ùå API not available, using simulated data\")\n",
    "    # Create simulated data\n",
    "    np.random.seed(42)\n",
    "    route_data = {\n",
    "        'visualizations': {\n",
    "            'scatter_data': [\n",
    "                {'x': np.random.uniform(50, 500), 'y': np.random.randint(5, 50), \n",
    "                 'city': np.random.choice(['bergen', 'oslo', 'stavanger']), 'name': f'Route_{i}'}\n",
    "                for i in range(50)\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Cell 3: Create DataFrame\n",
    "print(\"\\nüìä Creating DataFrame for analysis...\")\n",
    "scatter_data = route_data.get('visualizations', {}).get('scatter_data', [])\n",
    "df = pd.DataFrame(scatter_data)\n",
    "\n",
    "if not df.empty:\n",
    "    print(f\"‚úÖ Loaded {len(df)} routes\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"‚ùå No data available\")\n",
    "    # Create dummy data\n",
    "    df = pd.DataFrame({\n",
    "        'x': np.random.uniform(50, 500, 50),\n",
    "        'y': np.random.randint(5, 50, 50),\n",
    "        'city': np.random.choice(['bergen', 'oslo', 'stavanger', 'trondheim'], 50)\n",
    "    })\n",
    "\n",
    "# Cell 4: Descriptive Statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüìà Basic Statistics:\")\n",
    "print(df[['x', 'y']].describe())\n",
    "\n",
    "print(\"\\nüèôÔ∏è Routes by City:\")\n",
    "print(df['city'].value_counts())\n",
    "\n",
    "# Cell 5: Data Visualization\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA VISUALIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Figure 1: Distribution of Route Distances\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['x'], bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Route Distances', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Distance (nautical miles)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Figure 2: Distance vs Waypoints\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(df['x'], df['y'], c=pd.factorize(df['city'])[0], \n",
    "                      alpha=0.6, cmap='viridis', s=50)\n",
    "plt.title('Distance vs Waypoints by City', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Distance (nm)')\n",
    "plt.ylabel('Number of Waypoints')\n",
    "plt.colorbar(scatter, label='City')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cell 6: Statistical Analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Correlation analysis\n",
    "correlation = df[['x', 'y']].corr().iloc[0,1]\n",
    "print(f\"üìä Correlation between distance and waypoints: {correlation:.3f}\")\n",
    "\n",
    "# T-test between city groups (simplified)\n",
    "if 'city' in df.columns and len(df['city'].unique()) >= 2:\n",
    "    cities = df['city'].unique()[:2]\n",
    "    group1 = df[df['city'] == cities[0]]['x']\n",
    "    group2 = df[df['city'] == cities[1]]['x']\n",
    "    \n",
    "    if len(group1) > 1 and len(group2) > 1:\n",
    "        t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "        print(f\"üìã T-test between {cities[0]} and {cities[1]}:\")\n",
    "        print(f\"   t-statistic = {t_stat:.3f}, p-value = {p_value:.3f}\")\n",
    "\n",
    "# Cell 7: Machine Learning - Anomaly Detection\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MACHINE LEARNING: ANOMALY DETECTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare features\n",
    "features = df[['x', 'y']].fillna(0)\n",
    "if len(features) > 10:\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Apply Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    df['anomaly_score'] = iso_forest.fit_predict(features_scaled)\n",
    "    df['is_outlier'] = df['anomaly_score'] == -1\n",
    "    \n",
    "    outliers = df[df['is_outlier']]\n",
    "    print(f\"üîç Found {len(outliers)} outlier routes ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if not outliers.empty:\n",
    "        print(\"\\nüìù Sample outliers:\")\n",
    "        print(outliers[['x', 'y', 'city']].head())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough data for anomaly detection\")\n",
    "\n",
    "# Cell 8: Geospatial Analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GEOSPATIAL ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create interactive map\n",
    "print(\"\\nüó∫Ô∏è Creating interactive heatmap...\")\n",
    "\n",
    "# Sample coordinates for Norwegian coast (in reality, use actual waypoints)\n",
    "norway_coords = [\n",
    "    [58.1467, 8.0980], [58.9699, 5.7331], [60.3913, 5.3221],\n",
    "    [59.9139, 10.7522], [63.4305, 10.3951], [62.4722, 6.1497]\n",
    "]\n",
    "\n",
    "# Create map centered on Norway\n",
    "m = folium.Map(location=[63.0, 10.0], zoom_start=5, tiles='CartoDB positron')\n",
    "\n",
    "# Add heatmap\n",
    "HeatMap(norway_coords * 5, radius=15, blur=10).add_to(m)\n",
    "\n",
    "# Add markers for major ports\n",
    "ports = {\n",
    "    'Bergen': [60.3913, 5.3221],\n",
    "    'Oslo': [59.9139, 10.7522],\n",
    "    'Stavanger': [58.9699, 5.7331],\n",
    "    'Trondheim': [63.4305, 10.3951],\n",
    "    '√Ölesund': [62.4722, 6.1497]\n",
    "}\n",
    "\n",
    "for port, coords in ports.items():\n",
    "    folium.Marker(\n",
    "        coords,\n",
    "        popup=f\"<b>{port}</b><br>Major Norwegian Port\",\n",
    "        icon=folium.Icon(color='blue', icon='anchor')\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display map\n",
    "print(\"‚úÖ Map created successfully\")\n",
    "display(m)  # This works in Jupyter\n",
    "# To save: m.save('maritime_heatmap.html')\n",
    "\n",
    "# Cell 9: Business Insights\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BUSINESS INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"1. Route Optimization: Average distance shows potential for optimization\")\n",
    "print(\"2. Outlier Detection: Identified unusual routes for further investigation\")\n",
    "print(\"3. City Patterns: Different cities show distinct route characteristics\")\n",
    "\n",
    "print(\"\\nüéØ Recommendations:\")\n",
    "print(\"1. Implement real-time route optimization for fuel savings\")\n",
    "print(\"2. Set up automated alerts for anomalous routes\")\n",
    "print(\"3. Develop predictive maintenance based on route patterns\")\n",
    "\n",
    "# Cell 10: Export Analysis Results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPORTING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save analysis summary\n",
    "analysis_summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'total_routes_analyzed': len(df),\n",
    "    'average_distance': float(df['x'].mean()),\n",
    "    'average_waypoints': float(df['y'].mean()),\n",
    "    'outliers_detected': len(outliers) if 'outliers' in locals() else 0,\n",
    "    'correlation_distance_waypoints': float(correlation)\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('analysis_results.json', 'w') as f:\n",
    "    json.dump(analysis_summary, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Analysis results saved to 'analysis_results.json'\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYSIS COMPLETE - Ready for Data Science Portfolio!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
