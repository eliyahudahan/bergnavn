===== GROUP START =====


--- FILE: backend/ml/recommendation_engine.py ---
"""
EMPIRICAL ROUTE RECOMMENDER - Evidence-Based Vessel Routing
Recommends optimal routes based on NCA RouteInfo.no RTZ data with DB integration
Data Sources: Norwegian Coastal Administration RouteInfo.no, MET Norway, AIS data
NO TOURIST WAYPOINTS - Only technical maritime waypoints from RTZ files
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import logging
import json
import os
from pathlib import Path
from math import radians, sin, cos, sqrt, atan2

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class RouteRecommendation:
    """Empirical route recommendation with validation metrics"""
    route_id: str
    origin: str
    destination: str
    estimated_duration_hours: float
    duration_confidence_interval: Tuple[float, float]
    fuel_consumption_tons: float
    fuel_confidence_interval: Tuple[float, float]
    weather_risk_score: float
    eem_savings_potential: float
    recommendation_confidence: float
    data_sources: List[str]

class EmpiricalRouteRecommender:
    """
    Empirical route recommender using NCA RouteInfo.no RTZ data with DB integration
    Focuses on fuel optimization and EEM effectiveness with real route data
    NO TOURIST WAYPOINTS - Only technical maritime navigation points
    """
    
    def __init__(self):
        self.algorithm_version = "v3.2_db_integration"
        self.logger = logging.getLogger(__name__)
        self.route_data = self._load_route_data()
        self.weather_patterns = self._load_weather_patterns()
    
    def _haversine_distance(self, lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """Calculate distance between two coordinates in nautical miles"""
        R = 6371  # Earth radius in kilometers
        
        dlat = radians(lat2 - lat1)
        dlon = radians(lon2 - lon1)
        
        a = (sin(dlat/2) * sin(dlat/2) + 
             cos(radians(lat1)) * cos(radians(lat2)) * 
             sin(dlon/2) * sin(dlon/2))
        c = 2 * atan2(sqrt(a), sqrt(1-a))
        
        distance_km = R * c
        return distance_km / 1.852  # Convert to nautical miles
    
    def _calculate_route_distance(self, waypoints: List[Dict]) -> float:
        """Calculate total route distance from technical waypoints"""
        if len(waypoints) < 2:
            return 0.0
        
        total_distance = 0.0
        for i in range(len(waypoints) - 1):
            wp1 = waypoints[i]
            wp2 = waypoints[i + 1]
            
            distance = self._haversine_distance(
                wp1['lat'], wp1['lon'],
                wp2['lat'], wp2['lon']
            )
            total_distance += distance
        
        return round(total_distance, 1)
    
    def _extract_route_info_from_rtz(self, filename: str) -> Tuple[str, str]:
        """Extract origin and destination from RTZ filename"""
        # RTZ file naming convention: NCA_Origin_Destination.rtz
        name_only = filename.replace('.rtz', '').replace('.json', '')
        parts = name_only.split('_')
        
        if len(parts) >= 3 and parts[0] == 'NCA':
            origin = parts[1].lower()
            destination = parts[2].lower()
            return origin, destination
        
        # Fallback for RTZ files
        known_ports = ['bergen', 'trondheim', 'stavanger', 'oslo', 'alesund', 
                      'fedjeosen', 'halten', 'skudefjorden']
        
        for port in known_ports:
            if port in name_only.lower():
                remaining = name_only.lower().replace(port, '').strip('_')
                other_ports = [p for p in known_ports if p in remaining and p != port]
                if other_ports:
                    return port, other_ports[0]
        
        return 'unknown', 'unknown'
    
    def _load_route_data(self) -> Dict:
        """
        Load route data from DATABASE first, then fallback to RTZ files
        Priority: Database > RTZ files > Fallback data
        """
        # Try to load from database first
        db_routes = self._load_routes_from_db()
        if db_routes:
            self.logger.info(f"Loaded {len(db_routes)} routes from database")
            return db_routes
        
        # Fallback to RTZ files
        rtz_routes = self._load_from_rtz_files()
        if rtz_routes:
            self.logger.info(f"Loaded {len(rtz_routes)} routes from RTZ files")
            return rtz_routes
        
        # Final fallback
        self.logger.warning("No routes found, using fallback data")
        return self._get_fallback_data()
    
    def _load_routes_from_db(self) -> Dict:
        """Load routes from PostgreSQL database"""
        try:
            # Import inside function to avoid circular imports
            from backend.models.route import Route
            from backend.models.waypoint import Waypoint
            from backend.database.session import get_db
            
            route_data = {}
            
            with get_db() as db:
                routes = db.query(Route).filter(
                    Route.data_source.like('%NCA%') | Route.data_source.like('%RouteInfo%')
                ).all()
                
                if not routes:
                    return {}
                
                for route in routes:
                    # Get waypoints for this route
                    waypoints = [
                        {
                            'name': wp.name, 
                            'lat': wp.latitude, 
                            'lon': wp.longitude,
                            'order_index': wp.order_index
                        }
                        for wp in route.waypoints.order_by(Waypoint.order_index).all()
                    ]
                    
                    # Calculate distance if not in database
                    if route.distance_nm and route.distance_nm > 0:
                        distance_nm = route.distance_nm
                    else:
                        distance_nm = self._calculate_route_distance(waypoints)
                    
                    route_key = f"{route.origin or 'unknown'}_{route.destination or 'unknown'}"
                    
                    route_data[route_key] = {
                        'distance_nm': distance_nm,
                        'base_duration_hours': route.estimated_duration or self._estimate_duration(distance_nm),
                        'duration_ci': (
                            round((route.estimated_duration or self._estimate_duration(distance_nm)) * 0.9, 1),
                            round((route.estimated_duration or self._estimate_duration(distance_nm)) * 1.1, 1)
                        ),
                        'base_fuel_consumption': route.estimated_fuel_consumption or self._estimate_fuel(distance_nm),
                        'fuel_ci': (
                            round((route.estimated_fuel_consumption or self._estimate_fuel(distance_nm)) * 0.9, 1),
                            round((route.estimated_fuel_consumption or self._estimate_fuel(distance_nm)) * 1.1, 1)
                        ),
                        'typical_weather_impact': 1.12,
                        'eem_effectiveness': 0.087,
                        'data_source': route.data_source or 'Database',
                        'sample_size': 1,
                        'waypoints': waypoints,
                        'file_source': 'database',
                        'is_technical': True,
                        'route_id': route.id
                    }
                
                return route_data
                
        except Exception as e:
            self.logger.error(f"Database loading failed: {e}")
            return {}
    
    def _load_from_rtz_files(self) -> Dict:
        """
        Load route data from RTZ files ONLY - no tourist waypoints
        Sources: Norwegian Coastal Administration RouteInfo.no RTZ files
        """
        route_data = {}
        base_path = "backend/assets/routeinfo_routes"
        
        if not os.path.exists(base_path):
            self.logger.error(f"Route data path not found: {base_path}")
            return {}
        
        # Find all RTZ files in all subdirectories - NO JSON WAYPOINT FILES
        rtz_files = list(Path(base_path).rglob("*.rtz"))
        self.logger.info(f"Found {len(rtz_files)} RTZ files in route directories")
        
        valid_routes_loaded = 0
        
        for rtz_file in rtz_files:
            try:
                # Parse RTZ file to extract technical waypoints
                from backend.services.rtz_parser import parse_rtz
                routes_data = parse_rtz(str(rtz_file))
                
                if not routes_data:
                    self.logger.warning(f"Skipping {rtz_file.name}: no routes parsed")
                    continue
                
                # Use first route from RTZ file
                route_info = routes_data[0]
                waypoints = route_info.get('waypoints', [])
                
                if len(waypoints) < 2:
                    self.logger.warning(f"Skipping {rtz_file.name}: insufficient waypoints")
                    continue
                
                # Extract route information from RTZ filename
                origin, destination = self._extract_route_info_from_rtz(rtz_file.name)
                
                if origin == 'unknown' or destination == 'unknown':
                    self.logger.warning(f"Could not extract route info from {rtz_file.name}")
                    # Use first and last waypoint coordinates as fallback
                    origin = f"point_{waypoints[0]['lat']:.2f}_{waypoints[0]['lon']:.2f}"
                    destination = f"point_{waypoints[-1]['lat']:.2f}_{waypoints[-1]['lon']:.2f}"
                
                route_key = f"{origin}_{destination}"
                
                # Calculate real distance from technical waypoints
                distance_nm = self._calculate_route_distance(waypoints)
                
                if distance_nm == 0:
                    self.logger.warning(f"Skipping {route_key}: zero distance calculated")
                    continue
                
                # Estimate performance metrics based on distance
                base_duration_hours = self._estimate_duration(distance_nm)
                base_fuel_consumption = self._estimate_fuel(distance_nm)
                
                route_data[route_key] = {
                    'distance_nm': distance_nm,
                    'base_duration_hours': base_duration_hours,
                    'duration_ci': (
                        round(base_duration_hours * 0.9, 1),
                        round(base_duration_hours * 1.1, 1)
                    ),
                    'base_fuel_consumption': base_fuel_consumption,
                    'fuel_ci': (
                        round(base_fuel_consumption * 0.9, 1),
                        round(base_fuel_consumption * 1.1, 1)
                    ),
                    'typical_weather_impact': 1.12,
                    'eem_effectiveness': 0.087,  # 8.7% from specification
                    'data_source': 'Norwegian Coastal Administration RouteInfo.no RTZ',
                    'sample_size': 1,  # Official authoritative data
                    'waypoints': waypoints,
                    'file_source': str(rtz_file),
                    'is_technical': True  # ✅ MARK: Technical waypoints only
                }
                
                valid_routes_loaded += 1
                self.logger.info(f"Loaded RTZ route: {route_key} ({distance_nm} nm) from {rtz_file.name}")
                
            except Exception as e:
                self.logger.error(f"Error loading RTZ file {rtz_file}: {e}")
        
        self.logger.info(f"Successfully loaded {valid_routes_loaded} valid RTZ routes")
        return route_data
    
    def _get_fallback_data(self) -> Dict:
        """Fallback data if no routes available - ONLY FOR DEVELOPMENT"""
        self.logger.warning("USING FALLBACK DATA - FOR DEVELOPMENT ONLY")
        return {
            'bergen_fedjeosen': {
                'distance_nm': 31.3,
                'base_duration_hours': 4.5,
                'duration_ci': (4.0, 5.0),
                'base_fuel_consumption': 31.0,
                'fuel_ci': (28.3, 33.7),
                'typical_weather_impact': 1.08,
                'eem_effectiveness': 0.087,
                'data_source': 'NCA RouteInfo.no RTZ - Bergen Fedjeosen',
                'sample_size': 1,
                'waypoints': [
                    {'name': 'bergen_harbor', 'lat': 60.3913, 'lon': 5.3221},
                    {'name': 'fedjeosen_entrance', 'lat': 60.7789, 'lon': 4.7150}
                ],
                'file_source': 'fallback_rtz',
                'is_technical': True
            },
            'trondheim_halten': {
                'distance_nm': 143.2,
                'base_duration_hours': 18.0,
                'duration_ci': (16.0, 20.0),
                'base_fuel_consumption': 142.5,
                'fuel_ci': (130.1, 154.9),
                'typical_weather_impact': 1.25,
                'eem_effectiveness': 0.087,
                'data_source': 'NCA RouteInfo.no RTZ - Trondheim Halten',
                'sample_size': 1,
                'waypoints': [
                    {'name': 'trondheim_harbor', 'lat': 63.4305, 'lon': 10.3951},
                    {'name': 'halten_bank', 'lat': 64.1667, 'lon': 10.3333}
                ],
                'file_source': 'fallback_rtz',
                'is_technical': True
            }
        }
    
    def _estimate_duration(self, distance_nm: float) -> float:
        """Estimate duration based on distance (nautical miles)"""
        # Average speed: 15 knots for coastal routes
        base_hours = distance_nm / 15.0
        return round(base_hours, 1)
    
    def _estimate_fuel(self, distance_nm: float) -> float:
        """Estimate fuel consumption based on distance"""
        # Average consumption: 1 ton per nautical mile for medium vessels
        base_fuel = distance_nm * 1.0
        return round(base_fuel, 1)
    
    def _load_weather_patterns(self) -> Dict:
        """
        Load empirical weather patterns for route planning
        Sources: Norwegian Meteorological Institute, historical data 2020-2024
        """
        return {
            'summer': {
                'wind_impact': 1.08,
                'wave_impact': 1.05,
                'confidence': 0.85,
                'data_source': 'Summer season averages 2020-2024',
                'sample_months': 20
            },
            'winter': {
                'wind_impact': 1.25,
                'wave_impact': 1.35,
                'confidence': 0.78,
                'data_source': 'Winter season averages 2020-2024',
                'sample_months': 20
            },
            'spring_autumn': {
                'wind_impact': 1.15,
                'wave_impact': 1.18,
                'confidence': 0.82,
                'data_source': 'Transition season averages',
                'sample_months': 40
            }
        }
    
    def get_available_routes(self) -> List[str]:
        """Return list of all available routes with NCA data"""
        return list(self.route_data.keys())
    
    def get_route_waypoints(self, route_key: str) -> Optional[List[Dict]]:
        """Get technical waypoints for a specific route"""
        route_data = self.route_data.get(route_key)
        return route_data.get('waypoints') if route_data else None
    
    def recommend_optimal_routes(self, 
                               vessel_data: Dict,
                               weather_forecast: Dict,
                               max_recommendations: int = 3) -> List[RouteRecommendation]:
        """
        Recommend optimal routes based on NCA RouteInfo.no RTZ performance data
        Uses only technical waypoints - no tourist points
        """
        try:
            vessel_type = vessel_data.get('type', 'container')
            current_location = vessel_data.get('current_location', 'bergen')
            destination_preferences = vessel_data.get('destinations', [])
            
            # If no specific destinations provided, recommend from available routes
            if not destination_preferences:
                destination_preferences = [
                    route.split('_')[1] for route in self.route_data.keys() 
                    if route.startswith(current_location + '_')
                ]
            
            recommendations = []
            
            for destination in destination_preferences:
                route_key = f"{current_location}_{destination}"
                route_data = self.route_data.get(route_key)
                
                if not route_data:
                    self.logger.warning(f"No data for route: {route_key}")
                    continue
                
                # Verify this is technical data only
                if not route_data.get('is_technical', False):
                    self.logger.warning(f"Skipping non-technical route: {route_key}")
                    continue
                
                # Calculate weather-adjusted performance
                weather_adjustment = self._calculate_weather_adjustment(weather_forecast)
                adjusted_duration = route_data['base_duration_hours'] * weather_adjustment
                adjusted_fuel = route_data['base_fuel_consumption'] * weather_adjustment
                
                # Calculate confidence intervals
                duration_ci = self._calculate_adjusted_ci(
                    route_data['duration_ci'], weather_adjustment
                )
                fuel_ci = self._calculate_adjusted_ci(
                    route_data['fuel_ci'], weather_adjustment
                )
                
                # Weather risk assessment
                weather_risk = self._assess_weather_risk(weather_forecast)
                
                # EEM savings potential (8.7% from specification)
                eem_savings = route_data['eem_effectiveness']
                
                # Recommendation confidence
                confidence = self._calculate_recommendation_confidence(
                    route_data, weather_forecast, vessel_type
                )
                
                recommendation = RouteRecommendation(
                    route_id=route_data.get('route_id', route_key),
                    origin=current_location,
                    destination=destination,
                    estimated_duration_hours=round(adjusted_duration, 1),
                    duration_confidence_interval=(
                        round(duration_ci[0], 1), round(duration_ci[1], 1)
                    ),
                    fuel_consumption_tons=round(adjusted_fuel, 1),
                    fuel_confidence_interval=(
                        round(fuel_ci[0], 1), round(fuel_ci[1], 1)
                    ),
                    weather_risk_score=round(weather_risk, 2),
                    eem_savings_potential=round(eem_savings, 3),
                    recommendation_confidence=round(confidence, 2),
                    data_sources=[
                        route_data['data_source'],
                        'Norwegian Meteorological Institute',
                        'Kystverket AIS Data'
                    ]
                )
                
                recommendations.append(recommendation)
            
            # Sort by recommendation confidence and return top N
            recommendations.sort(key=lambda x: x.recommendation_confidence, reverse=True)
            return recommendations[:max_recommendations]
            
        except Exception as e:
            self.logger.error(f"Route recommendation failed: {str(e)}")
            return []
    
    def _calculate_weather_adjustment(self, weather_forecast: Dict) -> float:
        """Calculate weather impact adjustment based on forecast"""
        wind_speed = weather_forecast.get('wind_speed', 0)
        wave_height = weather_forecast.get('wave_height', 0)
        season = weather_forecast.get('season', 'spring_autumn')
        
        # Base adjustment from seasonal patterns
        base_adjustment = self.weather_patterns[season]['wind_impact']
        
        # Additional adjustment for extreme conditions
        if wind_speed > 20:
            wind_adjustment = (wind_speed - 20) * 0.02
            base_adjustment += min(wind_adjustment, 0.15)
        
        if wave_height > 3.0:
            wave_adjustment = (wave_height - 3.0) * 0.05
            base_adjustment += min(wave_adjustment, 0.20)
            
        return round(base_adjustment, 3)
    
    def _calculate_adjusted_ci(self, original_ci: Tuple[float, float], 
                             adjustment: float) -> Tuple[float, float]:
        """Calculate adjusted confidence interval"""
        return (original_ci[0] * adjustment, original_ci[1] * adjustment)
    
    def _assess_weather_risk(self, weather_forecast: Dict) -> float:
        """Assess weather risk on 0-1 scale"""
        wind_speed = weather_forecast.get('wind_speed', 0)
        wave_height = weather_forecast.get('wave_height', 0)
        
        risk = 0.0
        
        if wind_speed > 25:
            risk += 0.6
        elif wind_speed > 20:
            risk += 0.4
        elif wind_speed > 15:
            risk += 0.2
            
        if wave_height > 4.0:
            risk += 0.4
        elif wave_height > 2.5:
            risk += 0.2
            
        return min(risk, 1.0)
    
    def _calculate_recommendation_confidence(self, 
                                          route_data: Dict,
                                          weather_forecast: Dict,
                                          vessel_type: str) -> float:
        """Calculate overall recommendation confidence"""
        # Higher confidence for technical data
        base_confidence = 0.95 if route_data.get('is_technical') else 0.7
        
        # Weather forecast confidence impact
        weather_confidence = self.weather_patterns[
            weather_forecast.get('season', 'spring_autumn')
        ]['confidence']
        
        # Vessel type match confidence
        vessel_confidence = 0.9 if vessel_type in ['container', 'bulk_carrier'] else 0.7
        
        return (base_confidence + weather_confidence + vessel_confidence) / 3

# Testing with real route data
if __name__ == "__main__":
    recommender = EmpiricalRouteRecommender()
    
    print("=== ROUTE RECOMMENDER - DB INTEGRATION ===")
    print(f"Available routes: {', '.join(recommender.get_available_routes())}")
    
    # Test with realistic vessel and weather data
    vessel_data = {
        'type': 'container',
        'current_location': 'bergen',
        'destinations': []  # Will auto-discover from available routes
    }
    
    weather_forecast = {
        'wind_speed': 15,
        'wave_height': 1.8,
        'season': 'summer'
    }
    
    recommendations = recommender.recommend_optimal_routes(
        vessel_data, weather_forecast, max_recommendations=5
    )
    
    print(f"\n=== TOP {len(recommendations)} ROUTE RECOMMENDATIONS ===")
    for i, rec in enumerate(recommendations, 1):
        print(f"\nRecommendation #{i}: {rec.origin.upper()} → {rec.destination.upper()}")
        print(f"  Duration: {rec.estimated_duration_hours}h ({rec.duration_confidence_interval[0]}-{rec.duration_confidence_interval[1]}h)")
        print(f"  Fuel: {rec.fuel_consumption_tons}t ({rec.fuel_confidence_interval[0]}-{rec.fuel_confidence_interval[1]}t)")
        print(f"  Weather Risk: {rec.weather_risk_score}/1.0")
        print(f"  EEM Savings Potential: {rec.eem_savings_potential:.1%}")
        print(f"  Recommendation Confidence: {rec.recommendation_confidence:.0%}")
        print(f"  Data Sources: {', '.join(rec.data_sources)}")
    
    print(f"\n=== DATA SOURCE SUMMARY ===")
    for route_key in recommender.get_available_routes():
        route_data = recommender.route_data[route_key]
        source = route_data['file_source']
        source_type = "DATABASE" if source == 'database' else "RTZ FILE" if 'rtz' in source else "FALLBACK"
        technical_status = "TECHNICAL" if route_data.get('is_technical', False) else "NON-TECHNICAL"
        print(f"  {route_key}: {route_data['distance_nm']} nm ({source_type}, {technical_status})")

--- FILE: backend/ml/validation_engine.py ---
"""
Statistical Validation Engine for Maritime Fuel Optimization
Empirical validation framework with statistical significance testing
"""

import numpy as np
from scipy import stats
from typing import Dict, List, Tuple, Optional
import logging
from dataclasses import dataclass

@dataclass
class ValidationResult:
    """Container for statistical validation results"""
    is_significant: bool
    p_value: float
    confidence_interval: Tuple[float, float]
    effect_size: float
    sample_size: int
    test_type: str

class StatisticalValidator:
    """
    Empirical validation engine for maritime optimization algorithms
    Provides statistical significance testing and confidence intervals
    """
    
    def __init__(self, confidence_level: float = 0.95):
        self.confidence_level = confidence_level
        self.logger = logging.getLogger(__name__)
    
    def ab_test_significance(self, 
                           control_group: List[float],
                           treatment_group: List[float],
                           test_type: str = "t_test") -> ValidationResult:
        """
        Perform A/B test statistical significance analysis
        
        Args:
            control_group: Performance metrics from control group
            treatment_group: Performance metrics from treatment group  
            test_type: Type of statistical test ('t_test', 'mannwhitney')
            
        Returns:
            ValidationResult with statistical significance metrics
        """
        try:
            if len(control_group) < 2 or len(treatment_group) < 2:
                raise ValueError("Insufficient data for statistical testing")
            
            if test_type == "t_test":
                # Independent t-test for normally distributed data
                t_stat, p_value = stats.ttest_ind(treatment_group, control_group)
                effect_size = self._calculate_cohens_d(control_group, treatment_group)
            elif test_type == "mannwhitney":
                # Mann-Whitney U test for non-parametric data
                u_stat, p_value = stats.mannwhitneyu(treatment_group, control_group)
                effect_size = self._calculate_rank_biserial(control_group, treatment_group)
            else:
                raise ValueError(f"Unsupported test type: {test_type}")
            
            # Calculate confidence interval for mean difference
            ci_low, ci_high = self._calculate_confidence_interval(
                control_group, treatment_group
            )
            
            return ValidationResult(
                is_significant=p_value < (1 - self.confidence_level),
                p_value=float(p_value),
                confidence_interval=(float(ci_low), float(ci_high)),
                effect_size=float(effect_size),
                sample_size=len(control_group) + len(treatment_group),
                test_type=test_type
            )
            
        except Exception as e:
            self.logger.error(f"Statistical testing failed: {str(e)}")
            raise
    
    def _calculate_cohens_d(self, group1: List[float], group2: List[float]) -> float:
        """Calculate Cohen's d effect size for t-test"""
        n1, n2 = len(group1), len(group2)
        var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)
        
        pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))
        mean_diff = np.mean(group2) - np.mean(group1)
        
        return mean_diff / pooled_std if pooled_std != 0 else 0.0
    
    def _calculate_rank_biserial(self, group1: List[float], group2: List[float]) -> float:
        """Calculate rank-biserial correlation for Mann-Whitney test"""
        u_stat, _ = stats.mannwhitneyu(group1, group2)
        n1, n2 = len(group1), len(group2)
        
        return 1 - (2 * u_stat) / (n1 * n2)
    
    def _calculate_confidence_interval(self, 
                                    group1: List[float], 
                                    group2: List[float]) -> Tuple[float, float]:
        """Calculate confidence interval for mean difference"""
        mean1, mean2 = np.mean(group1), np.mean(group2)
        std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)
        n1, n2 = len(group1), len(group2)
        
        # Standard error of the difference
        se_diff = np.sqrt((std1**2 / n1) + (std2**2 / n2))
        
        # t-value for confidence level
        df = n1 + n2 - 2  # degrees of freedom
        t_val = stats.t.ppf((1 + self.confidence_level) / 2, df)
        
        margin_of_error = t_val * se_diff
        mean_diff = mean2 - mean1
        
        return (mean_diff - margin_of_error, mean_diff + margin_of_error)
    
    def validate_optimization_improvement(self,
                                        baseline_performance: List[float],
                                        optimized_performance: List[float],
                                        min_improvement: float = 0.05) -> Dict:
        """
        Validate that optimization provides statistically significant improvement
        
        Args:
            baseline_performance: Performance metrics before optimization
            optimized_performance: Performance metrics after optimization
            min_improvement: Minimum practical improvement threshold (5%)
            
        Returns:
            Dictionary with validation results and business interpretation
        """
        validation_result = self.ab_test_significance(
            baseline_performance, optimized_performance
        )
        
        # Calculate practical significance
        mean_baseline = np.mean(baseline_performance)
        mean_optimized = np.mean(optimized_performance)
        practical_improvement = (mean_optimized - mean_baseline) / mean_baseline
        
        return {
            "statistical_significance": validation_result.is_significant,
            "p_value": validation_result.p_value,
            "confidence_interval": validation_result.confidence_interval,
            "practical_improvement": practical_improvement,
            "practically_significant": practical_improvement >= min_improvement,
            "mean_baseline": mean_baseline,
            "mean_optimized": mean_optimized,
            "sample_size": validation_result.sample_size,
            "recommendation": self._generate_recommendation(validation_result, practical_improvement)
        }
    
    def _generate_recommendation(self, 
                               result: ValidationResult,
                               practical_improvement: float) -> str:
        """Generate business recommendation based on statistical results"""
        if not result.is_significant:
            return "Insufficient evidence: Optimization effect not statistically significant"
        
        if practical_improvement < 0.02:  # 2% threshold for practical significance
            return "Statistically significant but practically negligible improvement"
        
        if practical_improvement >= 0.05:  # 5% threshold for strong recommendation
            return "STRONG RECOMMENDATION: Statistically and practically significant improvement"
        
        return "MODERATE RECOMMENDATION: Statistically significant with modest practical improvement"

# Example usage and testing
if __name__ == "__main__":
    # Example A/B test data
    validator = StatisticalValidator()
    
    # Simulated fuel consumption data (tons per day)
    control_group = [45.2, 46.1, 44.8, 45.9, 46.3, 45.5, 44.9, 46.0, 45.7, 45.1]
    treatment_group = [42.1, 41.8, 42.5, 41.9, 42.3, 41.7, 42.0, 42.2, 41.6, 42.4]
    
    result = validator.ab_test_significance(control_group, treatment_group)
    print(f"Statistical significance: {result.is_significant}")
    print(f"P-value: {result.p_value:.4f}")
    print(f"Confidence interval: {result.confidence_interval}")
    print(f"Effect size: {result.effect_size:.3f}")

--- FILE: backend/models/route_leg.py ---
from backend.extensions import db
from geoalchemy2 import Geometry  # ✅ ADDED

class RouteLeg(db.Model):
    """
    A leg of a route, from waypoint A to waypoint B.
    """
    __tablename__ = "route_legs"

    id = db.Column(db.Integer, primary_key=True)
    leg_index = db.Column(db.Integer, nullable=False)
    geometry = db.Column(Geometry("LINESTRING", srid=4326))  # ✅ FIXED: Geometry not db.Geometry
    distance_nm = db.Column(db.Float)  # distance in nautical miles
    eta_minutes = db.Column(db.Float)  # estimated time

    # ForeignKey to base_routes
    base_route_id = db.Column(db.Integer, db.ForeignKey("base_routes.id"))
    
    # FIXED: String-based relationship
    base_route = db.relationship("BaseRoute", back_populates="legs")

    def __repr__(self):
        return f"<RouteLeg {self.leg_index} of route {self.base_route_id}>"

--- FILE: backend/models/ship.py ---
from datetime import datetime, UTC
from backend.extensions import db

class Ship(db.Model):
    __tablename__ = 'ships'

    id = db.Column(db.Integer, primary_key=True)
    mmsi = db.Column(db.Integer, unique=True, nullable=False)
    name = db.Column(db.String(100), nullable=False)
    type = db.Column(db.String(20), nullable=False)  # tanker, container, passenger, cargo, bulk_carrier, roro
    length = db.Column(db.Float, nullable=True)  # meters
    draft = db.Column(db.Float, nullable=True)   # meters
    built_year = db.Column(db.Integer, nullable=True)
    
    # NEW FIELDS FROM SANDBOX LEARNING
    home_port = db.Column(db.String(50), nullable=True)
    fuel_efficiency_profile = db.Column(db.JSON, nullable=True)  # Store type-specific coefficients
    operational_constraints = db.Column(db.JSON, nullable=True)  # Speed limits, draft restrictions
    alternative_fuel_capability = db.Column(db.Boolean, default=False)  # Methanol support
    
    created_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC), nullable=False)

    def __repr__(self):
        return f"<Ship {self.name} ({self.type})>"

    # UPDATED: Method to get ship-specific coefficients WITH METHANOL DATA
    def get_efficiency_coefficients(self):
        """Return ship type specific coefficients for calculations including methanol"""
        coefficients = {
            'tanker': {
                'base': 0.0060, 'optimal': 11.0, 'fuel_cost': 800, 'maintenance_impact': 0.15,
                'methanol_consumption_ratio': 1.8, 'methanol_cost': 1200, 'validation': 'maersk_validated'
            },
            'container': {
                'base': 0.0040, 'optimal': 14.0, 'fuel_cost': 750, 'maintenance_impact': 0.08,
                'methanol_consumption_ratio': 1.8, 'methanol_cost': 1150, 'validation': 'maersk_validated'
            },
            'bulk_carrier': {
                'base': 0.0055, 'optimal': 13.0, 'fuel_cost': 740, 'maintenance_impact': 0.11,
                'methanol_consumption_ratio': 1.8, 'methanol_cost': 1100, 'validation': 'sandbox_validated'
            },
            'roro': {
                'base': 0.0042, 'optimal': 15.0, 'fuel_cost': 770, 'maintenance_impact': 0.09,
                'methanol_consumption_ratio': 1.8, 'methanol_cost': 1180, 'validation': 'sandbox_validated'
            },
            'passenger': {
                'base': 0.0045, 'optimal': 16.0, 'fuel_cost': 780, 'maintenance_impact': 0.12,
                'methanol_consumption_ratio': 1.8, 'methanol_cost': 1250, 'validation': 'theoretical'
            },
            'cargo': {
                'base': 0.0050, 'optimal': 12.0, 'fuel_cost': 760, 'maintenance_impact': 0.10,
                'methanol_consumption_ratio': 1.8, 'methanol_cost': 1120, 'validation': 'theoretical'
            }
        }
        return coefficients.get(self.type, coefficients['cargo'])

--- FILE: backend/models/route_file.py ---
from backend.extensions import db
from datetime import datetime, UTC  # ✅ FIXED: Added UTC

class RouteFile(db.Model):
    """
    Stores uploaded RTZ route files metadata.
    """
    __tablename__ = "route_files"

    id = db.Column(db.Integer, primary_key=True)
    filename = db.Column(db.String(255), nullable=False)
    uploaded_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC))  # ✅ FIXED: UTC
    file_content = db.Column(db.LargeBinary, nullable=False)

    # FIXED: String-based relationship (no import needed)
    base_routes = db.relationship("BaseRoute", back_populates="route_file")

    def __repr__(self):
        return f"<RouteFile {self.filename}>"

--- FILE: backend/models/__init__.py ---
from .clock import Clock
from .cruise import Cruise
from .port import Port
from .locations import Location
from .route import Route
from .voyage_leg import VoyageLeg
from .weather_status import WeatherStatus

# EXISTING MODELS THAT WERE MISSING
from .base_route import BaseRoute
from .route_file import RouteFile  
from .route_leg import RouteLeg
from .waypoint import Waypoint
from .hazard_zone import HazardZone

# NEW MODELS - CRITICAL FOR METADATA REGISTRATION
from .ship import Ship
from .fuel_efficiency import FuelEfficiencyCalculation  
from .ship_coefficients import ShipTypeCoefficient

__all__ = [
    'Clock', 'Cruise', 'Port', 'Location', 'Route', 'VoyageLeg', 
    'WeatherStatus', 'BaseRoute', 'RouteFile', 'RouteLeg', 'Waypoint',
    'HazardZone', 'Ship', 'FuelEfficiencyCalculation', 'ShipTypeCoefficient'
]

--- FILE: backend/models/maritime_route.py ---
# models/maritime_route.py
# Unified Maritime Route Model for BergNavn
# -------------------------------------------------------
# This model merges the logical concepts of:
# - Route (high-level route entity)
# - BaseRoute (official RTZ route geometry)
# - RouteLeg (waypoints / geometry segments)
# - VoyageLeg (operational scheduling / ETA / distance)
#
# The unified structure supports:
# - Real-time AIS integration
# - Weather impact per segment
# - Safety constraints (wind farms, hazards, buffers)
# - Fuel optimization data
# - Day/Night conditions for each waypoint
# - Production-level performance & analytics
# -------------------------------------------------------

from datetime import datetime, UTC
from backend.extensions import db
from geoalchemy2 import Geometry


class MaritimeRoute(db.Model):
    __tablename__ = "maritime_routes"

    id = db.Column(db.Integer, primary_key=True)

    # Human metadata
    name = db.Column(db.String(255), nullable=False)
    description = db.Column(db.Text)

    # High-level geometry (full route polyline)
    geometry = db.Column(Geometry("LINESTRING", srid=4326))

    # Origin / destination
    origin_port_id = db.Column(db.Integer, db.ForeignKey("ports.id"))
    destination_port_id = db.Column(db.Integer, db.ForeignKey("ports.id"))

    origin_port = db.relationship("Port", foreign_keys=[origin_port_id])
    destination_port = db.relationship("Port", foreign_keys=[destination_port_id])

    # Operational metadata
    total_distance_nm = db.Column(db.Float)
    expected_duration_hours = db.Column(db.Float)
    is_active = db.Column(db.Boolean, default=True)

    # Relations
    legs = db.relationship(
        "MaritimeRouteLeg",
        back_populates="route",
        cascade="all, delete-orphan"
    )

    # Timestamps
    created_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC))
    updated_at = db.Column(
        db.DateTime,
        default=lambda: datetime.now(UTC),
        onupdate=lambda: datetime.now(UTC)
    )

    def __repr__(self):
        return f"<MaritimeRoute {self.name}>"


class MaritimeRouteLeg(db.Model):
    __tablename__ = "maritime_route_legs"

    id = db.Column(db.Integer, primary_key=True)
    route_id = db.Column(db.Integer, db.ForeignKey("maritime_routes.id"))

    route = db.relationship("MaritimeRoute", back_populates="legs")

    # Indexing & geometry
    leg_index = db.Column(db.Integer, nullable=False)
    geometry = db.Column(Geometry("LINESTRING", srid=4326))
    distance_nm = db.Column(db.Float)
    eta_minutes = db.Column(db.Float)

    # Weather & conditions
    wave_height_m = db.Column(db.Float)
    wind_speed_ms = db.Column(db.Float)
    daylight_condition = db.Column(db.String(50))  # day / night / twilight

    # Safety metadata
    hazard_nearby = db.Column(db.Boolean, default=False)
    safety_buffer_m = db.Column(db.Float)

    # Real-time AIS
    avg_speed_knots = db.Column(db.Float)
    congestion_index = db.Column(db.Float)

    # Runtime metadata
    created_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC))
    updated_at = db.Column(
        db.DateTime,
        default=lambda: datetime.now(UTC),
        onupdate=lambda: datetime.now(UTC)
    )

    def __repr__(self):
        return f"<MaritimeRouteLeg {self.leg_index} of route {self.route_id}>"


--- FILE: backend/models/locations.py ---
from backend.extensions import db

class Location(db.Model):
    __tablename__ = "locations"

    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False)
    country = db.Column(db.String(50), nullable=True)

    def __repr__(self):
        return f"<Location {self.name}, {self.country}>"


--- FILE: backend/models/port.py ---
from backend.extensions import db

class Port(db.Model):
    __tablename__ = 'ports'

    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False)
    latitude = db.Column(db.Float, nullable=False)
    longitude = db.Column(db.Float, nullable=False)
    country = db.Column(db.String(100), nullable=False)
    is_active = db.Column(db.Boolean, default=True, nullable=False)

    __table_args__ = (
        db.UniqueConstraint('name', 'country', name='uq_port_name_country'),
    )

    def __repr__(self):
        return f'<Port {self.name} ({self.latitude}, {self.longitude})>'


--- FILE: backend/models/base_route.py ---
from backend.extensions import db
from geoalchemy2 import Geometry  # ✅ ADDED

class BaseRoute(db.Model):
    """
    Represents a parsed RTZ route (top-level).
    """
    __tablename__ = "base_routes"

    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(255), nullable=False)
    description = db.Column(db.Text)
    geometry = db.Column(Geometry("LINESTRING", srid=4326))  # ✅ FIXED: Geometry not db.Geometry

    # ForeignKey to route_files
    route_file_id = db.Column(db.Integer, db.ForeignKey("route_files.id"))
    route_file = db.relationship("RouteFile", back_populates="base_routes")

    # Legs of this route
    legs = db.relationship("RouteLeg", back_populates="base_route")

    def __repr__(self):
        return f"<BaseRoute {self.name}>"

--- FILE: backend/models/weather_status.py ---
from backend.extensions import db
from datetime import datetime, UTC  # ✅ FIXED: Added import

class WeatherStatus(db.Model):
    __tablename__ = 'weather_statuses'

    id = db.Column(db.Integer, primary_key=True)
    port_id = db.Column(db.Integer, db.ForeignKey('ports.id'), nullable=False)
    datetime = db.Column(db.DateTime, default=lambda: datetime.now(UTC), nullable=False)  # ✅ FIXED: UTC default
    is_active = db.Column(db.Boolean, default=True, nullable=False)

    wind_speed = db.Column(db.Float)
    weather_condition = db.Column(db.String(100))
    
    sunrise = db.Column(db.Time)
    sunset = db.Column(db.Time)
    
    alert_level = db.Column(db.String(10))

    # ✅ FIXED: String-based relationship
    port = db.relationship("Port", backref="weather_statuses")

    def __repr__(self):
        return f"<WeatherStatus port:{self.port_id} condition:{self.weather_condition}>"

--- FILE: backend/models/cruise.py ---
from datetime import datetime, UTC
from backend.extensions import db

class Cruise(db.Model):
    __tablename__ = 'cruises'

    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(150), nullable=False)
    description = db.Column(db.Text, nullable=True)
    departure_date = db.Column(db.DateTime, nullable=False)
    return_date = db.Column(db.DateTime, nullable=False)
    origin = db.Column(db.String(100), nullable=True)    # City or location name
    destination = db.Column(db.String(100), nullable=False)
    origin_lat = db.Column(db.Float, nullable=True)  # Optional: for weather API (latitude)
    origin_lon = db.Column(db.Float, nullable=True)  # Optional: for weather API (longitude)
    destination_lat = db.Column(db.Float, nullable=True)
    destination_lon = db.Column(db.Float, nullable=True)
    price = db.Column(db.Float, nullable=False)
    capacity = db.Column(db.Integer, nullable=False, default=0)
    is_active = db.Column(db.Boolean, default=True)
    created_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC))
    updated_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC), onupdate=lambda: datetime.now(UTC))

    # FIXED: String-based relationships to avoid circular imports
    clock = db.relationship(
        "Clock",
        uselist=False,
        back_populates="cruise"
    )

    # (Temporarily disabled — Booking model currently removed)
    # bookings = db.relationship("Booking", back_populates="cruise")

    # FIXED: String-based relationship
    legs = db.relationship(
        "VoyageLeg",
        back_populates="cruise",
        cascade="all, delete-orphan",
        order_by="VoyageLeg.leg_order"
    )

    @property
    def duration_days(self):
        if self.departure_date and self.return_date:
            return (self.return_date - self.departure_date).days
        return None

    def __repr__(self):
        return f"<Cruise {self.title} ({self.origin} → {self.destination})>"

--- FILE: backend/models/hazard_zone.py ---
from backend.extensions import db
from geoalchemy2 import Geometry  # ✅ ADDED

class HazardZone(db.Model):
    """
    Hazardous area (turbines, tankers, currents).
    """
    __tablename__ = "hazard_zones"

    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(255), nullable=False)
    hazard_type = db.Column(db.String(100), nullable=False)
    geometry = db.Column(Geometry("POLYGON", srid=4326))  # ✅ FIXED: Geometry not db.Geometry
    risk_score = db.Column(db.Float, default=0.0)

    # No relationships - this is fine

    def __repr__(self):
        return f"<HazardZone {self.name} ({self.hazard_type})>"

--- FILE: backend/models/route.py ---
from backend.extensions import db

class Route(db.Model):
    __tablename__ = 'routes'

    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False)
    description = db.Column(db.Text)
    duration_days = db.Column(db.Float)
    total_distance_nm = db.Column(db.Float)
    origin = db.Column(db.String(100))  # ✅ ADDED: Route origin
    destination = db.Column(db.String(100))  # ✅ ADDED: Route destination
    is_active = db.Column(db.Boolean, default=True)

    # ✅ FIXED: String-based relationship - NO ABSOLUTE IMPORT!
    legs = db.relationship("VoyageLeg", backref="route", cascade="all, delete-orphan")

    def __repr__(self):
        return f"<Route {self.name}>"

--- FILE: backend/models/voyage_leg.py ---
from datetime import datetime, UTC
from backend.extensions import db

class VoyageLeg(db.Model):
    __tablename__ = 'voyage_legs'

    id = db.Column(db.Integer, primary_key=True)

    # Foreign keys
    cruise_id = db.Column(db.Integer, db.ForeignKey('cruises.id'), nullable=True)
    route_id = db.Column(db.Integer, db.ForeignKey('routes.id'), nullable=True)
    departure_port_id = db.Column(db.Integer, db.ForeignKey('ports.id', ondelete='SET NULL'), nullable=True)
    arrival_port_id = db.Column(db.Integer, db.ForeignKey('ports.id', ondelete='SET NULL'), nullable=True)

    # ✅ FIXED: String-based relationships - NO ABSOLUTE IMPORTS!
    departure_port = db.relationship("Port", foreign_keys=[departure_port_id])
    arrival_port = db.relationship("Port", foreign_keys=[arrival_port_id])
    cruise = db.relationship("Cruise", back_populates="legs")

    # Coordinates
    departure_lat = db.Column(db.Float, nullable=True)
    departure_lon = db.Column(db.Float, nullable=True)
    arrival_lat = db.Column(db.Float, nullable=True)
    arrival_lon = db.Column(db.Float, nullable=True)

    # Timing
    departure_time = db.Column(db.DateTime, nullable=False)
    arrival_time = db.Column(db.DateTime, nullable=False)

    # Sequence and status
    leg_order = db.Column(db.Integer, nullable=False, default=1)
    distance_nm = db.Column(db.Float, nullable=True)
    is_active = db.Column(db.Boolean, default=True, nullable=False)

    # Metadata
    created_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC), nullable=False)
    updated_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC),
                           onupdate=lambda: datetime.now(UTC), nullable=False)

    def __repr__(self):
        dep_name = self.departure_port.name if self.departure_port else "Unknown"
        arr_name = self.arrival_port.name if self.arrival_port else "Unknown"
        return f"<VoyageLeg {dep_name} → {arr_name} (Leg {self.leg_order})>"

--- FILE: backend/models/fuel_efficiency.py ---
from datetime import datetime, UTC
from backend.extensions import db

class FuelEfficiencyCalculation(db.Model):
    __tablename__ = 'fuel_efficiency_calculations'

    id = db.Column(db.Integer, primary_key=True)
    ship_id = db.Column(db.Integer, db.ForeignKey('ships.id'), nullable=False)
    voyage_leg_id = db.Column(db.Integer, db.ForeignKey('voyage_legs.id'), nullable=True)
    
    # Input parameters
    current_speed = db.Column(db.Float, nullable=False)
    weather_wind_speed = db.Column(db.Float, nullable=True)
    weather_wind_direction = db.Column(db.Float, nullable=True)
    
    # Calculation results
    optimal_speed = db.Column(db.Float, nullable=False)
    fuel_saving_percent = db.Column(db.Float, nullable=False)
    estimated_savings_usd_hour = db.Column(db.Float, nullable=False)
    
    # Enhanced metrics from sandbox
    efficiency_class = db.Column(db.String(10), nullable=True)
    confidence_score = db.Column(db.Float, nullable=True)
    algorithm_version = db.Column(db.String(20), default='v2.0_sandbox')
    
    # Alternative fuel calculations
    alternative_fuel_type = db.Column(db.String(20), nullable=True)
    alternative_fuel_savings = db.Column(db.Float, nullable=True)
    
    calculated_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC), nullable=False)
    
    # FIXED: String-based relationships
    ship = db.relationship("Ship", backref="fuel_calculations")
    voyage_leg = db.relationship("VoyageLeg", backref="fuel_calculations")

    def __repr__(self):
        return f"<FuelEfficiencyCalculation ship:{self.ship_id} saving:{self.fuel_saving_percent}%>"

    # REMOVED: calculate_optimal_speed should be in Ship class or service

--- FILE: backend/models/waypoint.py ---
from backend.extensions import db
from geoalchemy2 import Geometry  # ✅ ADDED

class Waypoint(db.Model):
    """
    A waypoint belonging to a route leg.
    """
    __tablename__ = "waypoints"

    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(255))
    position = db.Column(Geometry("POINT", srid=4326))  # ✅ FIXED: Geometry not db.Geometry
    order_index = db.Column(db.Integer, nullable=False)

    # ForeignKey to route_leg
    route_leg_id = db.Column(db.Integer, db.ForeignKey("route_legs.id"))

    def __repr__(self):
        return f"<Waypoint {self.name} (order: {self.order_index})>"

--- FILE: backend/models/clock.py ---
from datetime import datetime, UTC
from backend.extensions import db

class Clock(db.Model):
    __tablename__ = 'clocks'

    id = db.Column(db.Integer, primary_key=True)
    cruise_id = db.Column(db.Integer, db.ForeignKey('cruises.id'), nullable=False)
    timezone = db.Column(db.String(100), nullable=False)
    offset = db.Column(db.Integer, nullable=True)  # An Example: UTC+2 = 2
    created_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC))
    
    # FIXED: String-based relationship to avoid circular imports
    cruise = db.relationship("Cruise", back_populates="clock")

    def __repr__(self):
        return f"<Clock cruise_id={self.cruise_id} tz={self.timezone}>"

--- FILE: backend/models/ship_coefficients.py ---
from datetime import datetime, UTC
from backend.extensions import db

class ShipTypeCoefficient(db.Model):
    __tablename__ = 'ship_type_coefficients'

    id = db.Column(db.Integer, primary_key=True)
    ship_type = db.Column(db.String(20), unique=True, nullable=False)
    
    # Core coefficients from sandbox validation
    base_consumption_coef = db.Column(db.Float, nullable=False)  # Consumption per meter-length
    optimal_speed_knots = db.Column(db.Float, nullable=False)    # Speed for max efficiency
    fuel_cost_usd_tonne = db.Column(db.Float, nullable=False)    # Type-specific fuel costs
    maintenance_impact = db.Column(db.Float, nullable=False)     # Maintenance on efficiency
    
    # NEW: Methanol support based on Maersk data
    methanol_consumption_ratio = db.Column(db.Float, default=1.8)  # Based on Maersk: 1.8x more consumption
    methanol_cost_usd_tonne = db.Column(db.Float, default=1200)    # Methanol price based on Maersk data
    
    # Validation metadata
    validation_status = db.Column(db.String(20), default='validated')  # validated, sandbox_validated, theoretical
    last_calibration_date = db.Column(db.DateTime, default=lambda: datetime.now(UTC))
    
    created_at = db.Column(db.DateTime, default=lambda: datetime.now(UTC), nullable=False)

    def __repr__(self):
        return f"<ShipTypeCoefficient {self.ship_type}>"


# UPDATED: Complete data population with methanol coefficients
def populate_ship_coefficients():
    """Populate with validated coefficients including methanol data from Maersk"""
    coefficients_data = [
        {
            'ship_type': 'tanker', 
            'base_consumption_coef': 0.0060, 
            'optimal_speed_knots': 11.0, 
            'fuel_cost_usd_tonne': 800, 
            'maintenance_impact': 0.15,
            'methanol_consumption_ratio': 1.8,
            'methanol_cost_usd_tonne': 1200,
            'validation_status': 'maersk_validated'
        },
        {
            'ship_type': 'container', 
            'base_consumption_coef': 0.0040, 
            'optimal_speed_knots': 14.0, 
            'fuel_cost_usd_tonne': 750, 
            'maintenance_impact': 0.08,
            'methanol_consumption_ratio': 1.8,
            'methanol_cost_usd_tonne': 1150,
            'validation_status': 'maersk_validated'
        },
        {
            'ship_type': 'bulk_carrier', 
            'base_consumption_coef': 0.0055, 
            'optimal_speed_knots': 13.0, 
            'fuel_cost_usd_tonne': 740, 
            'maintenance_impact': 0.11,
            'methanol_consumption_ratio': 1.8,
            'methanol_cost_usd_tonne': 1100,
            'validation_status': 'sandbox_validated'
        },
        {
            'ship_type': 'roro', 
            'base_consumption_coef': 0.0042, 
            'optimal_speed_knots': 15.0, 
            'fuel_cost_usd_tonne': 770, 
            'maintenance_impact': 0.09,
            'methanol_consumption_ratio': 1.8,
            'methanol_cost_usd_tonne': 1180,
            'validation_status': 'sandbox_validated'
        },
        {
            'ship_type': 'passenger', 
            'base_consumption_coef': 0.0045, 
            'optimal_speed_knots': 16.0, 
            'fuel_cost_usd_tonne': 780, 
            'maintenance_impact': 0.12,
            'methanol_consumption_ratio': 1.8,
            'methanol_cost_usd_tonne': 1250,
            'validation_status': 'theoretical'
        },
        {
            'ship_type': 'cargo', 
            'base_consumption_coef': 0.0050, 
            'optimal_speed_knots': 12.0, 
            'fuel_cost_usd_tonne': 760, 
            'maintenance_impact': 0.10,
            'methanol_consumption_ratio': 1.8,
            'methanol_cost_usd_tonne': 1120,
            'validation_status': 'theoretical'
        }
    ]
    
    for data in coefficients_data:
        if not ShipTypeCoefficient.query.filter_by(ship_type=data['ship_type']).first():
            coefficient = ShipTypeCoefficient(**data)
            db.session.add(coefficient)
            print(f"✅ Added coefficients for {data['ship_type']}")
        else:
            print(f"⚠️ Coefficients for {data['ship_type']} already exist")
    
    db.session.commit()
    print("🎉 Ship coefficients population completed!")

--- FILE: backend/config/flags.py ---
# backend/config/flags.py

import os

# ניתן לשלוט דרך קובץ env או כאן ישירות
MAX_DUMMY_USERS = int(os.getenv("MAX_DUMMY_USERS", 5))
ENABLE_DUMMY_USERS = os.getenv("ENABLE_DUMMY_USERS", "true").lower() == "true"


--- FILE: backend/config/config.py ---
# backend/config/config.py - Configuration settings for BergNavn Maritime Application
import os
from dotenv import load_dotenv
from sqlalchemy.orm import declarative_base

# Load environment variables from .env file
load_dotenv()

DATABASE_URL = os.getenv("DATABASE_URL")
TEST_DATABASE_URL = os.getenv("TEST_DATABASE_URL")

if not DATABASE_URL:
    raise ValueError("❌ DATABASE_URL was not loaded properly! Check your .env file.")

Base = declarative_base()  # SQLAlchemy base model definition - FIXED deprecated import

class Config:
    """Main application configuration class with environment variables"""
    
    # Security settings for session management
    SECRET_KEY = os.getenv('SECRET_KEY', 'default-secret-key')
    
    # Database configuration for PostgreSQL connection
    DATABASE_URL = DATABASE_URL
    SQLALCHEMY_DATABASE_URI = DATABASE_URL
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # Debug and development settings
    DEBUG = os.getenv('DEBUG', 'False') == 'True'
    
    # Email configuration for SMTP server
    MAIL_SERVER = os.getenv('MAIL_SERVER', 'smtp.gmail.com')
    MAIL_PORT = int(os.getenv('MAIL_PORT', 587))
    MAIL_USE_TLS = os.getenv('MAIL_USE_TLS', 'True') == 'True'
    MAIL_USE_SSL = os.getenv('MAIL_USE_SSL', 'False') == 'True'
    MAIL_USERNAME = os.getenv('MAIL_USERNAME')
    MAIL_PASSWORD = os.getenv('MAIL_PASSWORD')
    
    # External API configurations for maritime data
    OPENWEATHER_API_KEY = os.getenv('OPENWEATHER_API_KEY')  # From environment only
    MET_NORWAY_USER_AGENT = 'BergNavnMaritime/2.0 (framgangsrik747@gmail.com)'
    
    # Application performance and cache settings
    CACHE_TIMEOUT = 600  # 10 minutes in seconds
    WEATHER_UPDATE_INTERVAL = 300000  # 5 minutes in milliseconds
    AIS_SOCKET_TIMEOUT = 30  # Socket timeout for AIS data in seconds


class TestingConfig(Config):
    """Testing configuration with PostgreSQL test database"""
    TESTING = True
    DEBUG = False
    
    # Use PostgreSQL for tests - supports spatial functions
    SQLALCHEMY_DATABASE_URI = TEST_DATABASE_URL
    
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    WTF_CSRF_ENABLED = False  # Disable CSRF protection for tests
    DATABASE_URL = TEST_DATABASE_URL
    
    # Disable external services for tests
    DISABLE_AIS_SERVICE = True
    FLASK_SKIP_SCHEDULER = True

--- FILE: backend/tests/ test_integration.py ---
"""
Integration Tests for RTZ Parser and Database Integration
Tests the complete pipeline from RTZ parsing to database storage
"""

import pytest
import tempfile
import os
from pathlib import Path
from xml.etree import ElementTree as ET

class TestRTZDatabaseIntegration:
    """Test RTZ parser integration with database"""
    
    def test_rtz_parser_technical_waypoints(self):
        """Test that RTZ parser only extracts technical waypoints"""
        from backend.services.rtz_parser import parse_rtz, _is_technical_waypoint
        
        # Test technical waypoint detection
        technical_wp = {'name': 'pilot_boarding', 'lat': 60.0, 'lon': 5.0}
        tourist_wp = {'name': 'nature_park', 'lat': 61.0, 'lon': 6.0}
        
        assert _is_technical_waypoint(technical_wp) == True
        assert _is_technical_waypoint(tourist_wp) == False
        assert _is_technical_waypoint({'name': None, 'lat': 62.0, 'lon': 7.0}) == True
    
    def test_rtz_parser_with_sample_data(self):
        """Test RTZ parser with sample RTZ data"""
        from backend.services.rtz_parser import parse_rtz
        
        # Create a temporary RTZ file for testing
        with tempfile.NamedTemporaryFile(mode='w', suffix='.rtz', delete=False) as f:
            # Simple RTZ-like XML structure
            f.write('''<?xml version="1.0" encoding="UTF-8"?>
            <route>
                <routeInfo>
                    <routeName>Test Route</routeName>
                </routeInfo>
                <waypoints>
                    <waypoint id="1">
                        <position>
                            <lat>60.3913</lat>
                            <lon>5.3221</lon>
                        </position>
                        <name>bergen_harbor</name>
                    </waypoint>
                    <waypoint id="2">
                        <position>
                            <lat>60.7789</lat>
                            <lon>4.7150</lon>
                        </position>
                        <name>fedjeosen_entrance</name>
                    </waypoint>
                </waypoints>
            </route>''')
            temp_file = f.name
        
        try:
            # Parse the test file
            routes = parse_rtz(temp_file)
            
            # Verify parsing results
            assert len(routes) == 1
            route = routes[0]
            
            assert route['route_name'] == 'Test Route'
            assert len(route['waypoints']) == 2
            assert route['waypoints_type'] == 'technical_only'
            assert route['total_distance_nm'] > 0
            
            # Verify waypoints are technical
            for wp in route['waypoints']:
                assert _is_technical_waypoint(wp) == True
            
        finally:
            # Clean up
            os.unlink(temp_file)
    
    def test_database_save_functionality(self):
        """Test saving parsed routes to database"""
        from backend.services.rtz_parser import save_rtz_routes_to_db
        
        # Create sample route data
        sample_routes = [
            {
                'route_name': 'Test Integration Route',
                'total_distance_nm': 45.2,
                'waypoints': [
                    {'name': 'test_point_1', 'lat': 59.91, 'lon': 10.75},
                    {'name': 'test_point_2', 'lat': 59.85, 'lon': 10.60}
                ],
                'legs': []
            }
        ]
        
        # Try to save to database
        saved_count = save_rtz_routes_to_db(sample_routes)
        
        # Should either save successfully or fail gracefully
        assert saved_count >= 0
        assert isinstance(saved_count, int)
    
    def test_recommendation_engine_db_integration(self):
        """Test that recommendation engine can use database data"""
        from backend.ml.recommendation_engine import EmpiricalRouteRecommender
        
        # Initialize recommender
        recommender = EmpiricalRouteRecommender()
        
        # Should be able to load routes (even if empty)
        routes = recommender.get_available_routes()
        assert isinstance(routes, list)
        
        # Test recommendation with sample data
        vessel_data = {
            'type': 'container',
            'current_location': 'bergen', 
            'destinations': ['oslo']
        }
        weather_forecast = {
            'wind_speed': 12,
            'wave_height': 1.5,
            'season': 'summer'
        }
        
        recommendations = recommender.recommend_optimal_routes(
            vessel_data, weather_forecast, max_recommendations=2
        )
        
        # Should return a list (may be empty if no matching routes)
        assert isinstance(recommendations, list)
    
    def test_validation_service_integration(self):
        """Test validation service with database integration"""
        from backend.services.validation_service import RouteValidation
        
        validator = RouteValidation()
        
        # Test with sample route data
        sample_route = {
            'origin': 'bergen',
            'destination': 'oslo', 
            'distance_nm': 310.0,
            'eem_savings_potential': 0.087
        }
        
        # Test fuel savings validation
        validation_result = validator.validate_fuel_savings(sample_route)
        
        # Should return structured validation results
        assert 'predicted_savings' in validation_result
        assert 'empirical_savings' in validation_result
        assert 'confidence_interval' in validation_result
        assert 'statistical_significance' in validation_result
        assert 'sample_size' in validation_result
        
        # Test safety validation
        safety_result = validator.validate_route_safety(
            {'waypoints': [{'lat': 59.91, 'lon': 10.75}]},
            {'wind_speed': 15, 'wave_height': 2.0}
        )
        
        assert 'safety_score' in safety_result
        assert 'overall_assessment' in safety_result

class TestIntegrationPipeline:
    """Test the complete integration pipeline"""
    
    def test_integration_script_structure(self):
        """Test that integration script has correct structure"""
        # This is a structural test - the script should run without syntax errors
        from backend.scripts.integration_script import integrate_all_rtz_files, verify_database_integration
        
        # These functions should exist and be callable
        assert callable(integrate_all_rtz_files)
        assert callable(verify_database_integration)
    
    def test_error_handling(self):
        """Test that integration handles errors gracefully"""
        from backend.services.rtz_parser import parse_rtz
        
        # Test with non-existent file
        routes = parse_rtz('/non/existent/file.rtz')
        assert routes == []  # Should return empty list, not crash
        
        # Test with invalid XML
        with tempfile.NamedTemporaryFile(mode='w', suffix='.rtz', delete=False) as f:
            f.write('Invalid XML content')
            temp_file = f.name
        
        try:
            routes = parse_rtz(temp_file)
            assert routes == []  # Should handle parse errors gracefully
        finally:
            os.unlink(temp_file)

if __name__ == "__main__":
    pytest.main([__file__, "-v"])

--- FILE: backend/tests/conftest.py ---
# backend/tests/conftest.py
import os
import sys
import pytest
from datetime import datetime, UTC

# Ensure project root is in PYTHONPATH
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from app import create_app
from backend.extensions import db
from backend.models.route import Route
from backend.models.voyage_leg import VoyageLeg
from backend.models.port import Port
from backend.models.weather_status import WeatherStatus

@pytest.fixture(scope="session")
def app():
    """Create application for the tests."""
    app = create_app(testing=True)
    
    with app.app_context():
        # Create all tables - PostgreSQL supports spatial functions
        db.create_all()
        
        yield app
        
        # Cleanup after all tests
        db.drop_all()

@pytest.fixture(autouse=True)
def app_context(app):
    """Automatically provide app context for tests."""
    with app.app_context():
        yield

@pytest.fixture(autouse=True)
def seed_test_data(app):
    """Seed test data for all tests."""
    with app.app_context():
        # Clear existing data
        try:
            db.session.query(WeatherStatus).delete()
            db.session.query(VoyageLeg).delete()
            db.session.query(Route).delete()
            db.session.query(Port).delete()
            db.session.commit()
        except:
            db.session.rollback()
            # If tables don't exist, create them
            db.create_all()

        # Create test ports
        bergen = Port(
            name="Bergen", 
            latitude=60.39299, 
            longitude=5.32415, 
            country="Norway", 
            is_active=True
        )
        oslo = Port(
            name="Oslo", 
            latitude=59.9139, 
            longitude=10.7522, 
            country="Norway", 
            is_active=True
        )
        trondheim = Port(
            name="Trondheim", 
            latitude=63.4305, 
            longitude=10.3951, 
            country="Norway", 
            is_active=True
        )

        db.session.add_all([bergen, oslo, trondheim])
        db.session.commit()

        # Create test route
        norwegian_route = Route(
            id=1, 
            name="Norwegian Fjords", 
            is_active=True
        )
        db.session.add(norwegian_route)
        db.session.commit()

        # Create test voyage legs - עם כל השדות הנדרשים
        legs = [
            (bergen, oslo, "2025-01-01 08:00:00", "2025-01-01 18:00:00", 1, 120.5),
            (oslo, trondheim, "2025-01-01 19:00:00", "2025-01-02 08:00:00", 2, 250.0)
        ]
        
        for dep, arr, dep_time, arr_time, leg_order, distance in legs:
            leg = VoyageLeg(
                route_id=norwegian_route.id,
                departure_port_id=dep.id,
                arrival_port_id=arr.id,
                departure_lat=dep.latitude,
                departure_lon=dep.longitude,
                arrival_lat=arr.latitude,
                arrival_lon=arr.longitude,
                departure_time=datetime.fromisoformat(dep_time.replace(' ', 'T')),
                arrival_time=datetime.fromisoformat(arr_time.replace(' ', 'T')),
                leg_order=leg_order,
                distance_nm=distance,
                is_active=True,
            )
            db.session.add(leg)
        db.session.commit()

        # Create test weather status
        bad_weather = WeatherStatus(
            port_id=trondheim.id,
            alert_level="red",
            is_active=True,
            datetime=datetime.now(UTC),
        )
        db.session.add(bad_weather)
        db.session.commit()

        yield

        # Final cleanup
        db.session.remove()

--- FILE: backend/tests/test_i18n.py ---
"""
Tests for internationalization (i18n) and translation functionality.
Tests cover translation structure, language consistency, and UI rendering.
"""

from backend.utils.translations import translations, translate
from app import create_app
import pytest


@pytest.fixture(scope="session")
def app():
    """Create Flask application with testing configuration."""
    app = create_app(testing=True)
    return app


def test_translations_structure():
    """
    Test that translation files have consistent structure.
    Verifies that all languages have the same keys and sections.
    """
    # Get available languages
    languages = list(translations.keys())
    assert len(languages) >= 2, "Should have at least two languages"
    
    # Compare structure between languages
    for i in range(len(languages)):
        for j in range(i + 1, len(languages)):
            lang1 = languages[i]
            lang2 = languages[j]
            
            # Compare top-level sections
            assert set(translations[lang1].keys()) == set(translations[lang2].keys()), \
                f"Sections mismatch between {lang1} and {lang2}"
            
            # Compare keys within each section
            for section in translations[lang1].keys():
                assert set(translations[lang1][section].keys()) == set(translations[lang2][section].keys()), \
                    f"Keys mismatch in section '{section}' between {lang1} and {lang2}"


def test_english_translations_exist():
    """
    Test that English translations are available and properly structured.
    English is the fallback language and should always be present.
    """
    assert 'en' in translations, "English translations must exist"
    assert isinstance(translations['en'], dict), "English translations should be a dictionary"
    assert len(translations['en']) > 0, "English translations should not be empty"


def test_norwegian_translations_exist():
    """
    Test that Norwegian translations are available.
    Norwegian is a primary language for this application.
    """
    assert 'no' in translations, "Norwegian translations must exist"
    assert isinstance(translations['no'], dict), "Norwegian translations should be a dictionary"
    assert len(translations['no']) > 0, "Norwegian translations should not be empty"


def test_translate_function():
    """
    Test the translate function with various inputs.
    """
    # Test existing key
    result = translate('home', 'en', 'global')
    assert result == 'Home'
    
    # Test fallback for non-existent key
    result = translate('nonexistent_key', 'en', 'global')
    # Should return the key itself or a fallback message
    assert 'nonexistent_key' in result or 'N/A' in result


def test_cruises_view_no_language(app):
    """
    Test that Norwegian language view renders correctly.
    Verifies no Python built-in methods are exposed in the rendered HTML.
    """
    with app.test_client() as client:
        # Try different cruise-related endpoints
        response = client.get("/cruises?lang=no")
        html_content = response.data.decode("utf-8")
        
        # Check if we got a successful response or redirect
        assert response.status_code in [200, 302, 308, 404]
        
        # If we got content, check for Python artifacts
        if response.status_code == 200:
            assert "<built-in method title" not in html_content.lower()
            assert "<built-in method" not in html_content.lower()

--- FILE: backend/tests/test_basic_models.py ---
"""
Basic model tests for BergNavn maritime application.
Tests cover fundamental database operations and model validation.
"""

import sys
import os
import pytest

# Add project root to PYTHONPATH to import create_app from app.py
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

from app import create_app
from backend.models.port import Port
from backend import db


@pytest.fixture(scope='module')
def test_app():
    """
    Create Flask application in 'testing' mode and push context.
    """
    app = create_app('testing')
    ctx = app.app_context()
    ctx.push()
    yield app
    ctx.pop()


@pytest.fixture(scope='module')
def init_database(test_app):
    """
    Run db.create_all() within application context and cleanup after.
    """
    db.create_all()
    yield db
    db.session.remove()
    db.drop_all()


def test_create_port(init_database):
    """
    Basic smoke test for Port model:
    Creation, saving, and retrieval with required coordinates.
    """
    # Create new instance with required latitude/longitude
    port = Port(
        name='Copenhagen', 
        country='Denmark',
        latitude=55.6761,  # Required field
        longitude=12.5683  # Required field
    )
    db.session.add(port)
    db.session.commit()

    # Verify the port was created successfully
    assert port.id is not None
    assert port.name == 'Copenhagen'
    assert port.country == 'Denmark'
    assert port.latitude == 55.6761
    assert port.longitude == 12.5683


def test_port_string_representation(init_database):
    """
    Test that Port string representation is meaningful.
    """
    port = Port(
        name='Oslo', 
        country='Norway',
        latitude=59.9139,
        longitude=10.7522
    )
    
    # Test string representation contains key information
    port_str = str(port)
    # The string representation should contain the port name and coordinates
    assert 'Oslo' in port_str
    assert '59.9139' in port_str  # latitude
    assert '10.7522' in port_str  # longitude

--- FILE: backend/tests/test_cruise.py ---


--- FILE: backend/tests/test_user.py ---


===== GROUP END =====
